{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb64930",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rospy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2556\\3351749482.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrospy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstd_msgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInt32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcv_bridge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCvBridge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rospy'"
     ]
    }
   ],
   "source": [
    "import rospy\n",
    "from std_msgs.msg import Int32\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['follow', 'stop', 'turn_left', 'turn_right', 'move_forward', 'move_backward'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(30,126)))\n",
    "model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.load_weights('action.h5')\n",
    "\n",
    "'''colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        #cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        #cv2.rectangle(output_frame,(384,0),(510,128),(0,255,0),-1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame'''\n",
    "\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    max_prob = 0\n",
    "    max_prob_index = -1\n",
    "    for num, prob in enumerate(res):\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            max_prob_index = num\n",
    "\n",
    "    cv2.putText(output_frame, actions[max_prob_index], (0, 85+max_prob_index*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    return output_frame, max_prob_index\n",
    "\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y, landmark_z]) \n",
    "            \n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list)) \n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list)) \n",
    "    \n",
    "    return temp_landmark_list\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Initialize ROS node\n",
    "rospy.init_node('action_detection_node', anonymous=True)\n",
    "\n",
    "# Create publisher for action topic\n",
    "action_publisher = rospy.Publisher('action', Int32, queue_size=10)\n",
    "\n",
    "# Create CvBridge object\n",
    "bridge = CvBridge()\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(3)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 720)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "use_brect = True\n",
    "\n",
    "with mp_hands.Hands(model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        debug_image = copy.deepcopy(image)\n",
    "        if not success:\n",
    "              print(\"Ignoring empty camera frame.\")\n",
    "              # If loading a video, use 'break' instead of 'continue'.\n",
    "              continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        handedness = results.multi_handedness\n",
    "        print(results)\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "              for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                               mp_drawing_styles.get_default_hand_landmarks_style(), \n",
    "                                               mp_drawing_styles.get_default_hand_connections_style())\n",
    "                    # Bounding box calculation\n",
    "                    brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                    \n",
    "                    # Landmark calculation\n",
    "                    landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                    # Conversion to relative coordinates / normalized coordinates\n",
    "                    pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "                    \n",
    "                    if len(pre_processed_landmark_list)==126: \n",
    "                        continue\n",
    "                    elif len(pre_processed_landmark_list)==63:\n",
    "                        pre_processed_landmark_list.extend(np.zeros(21*3))\n",
    "                    else:\n",
    "                        pre_processed_landmark_list.extend(np.zeros(21*6))\n",
    "                    \n",
    "                    # Drawing part\n",
    "                    image = draw_bounding_rect(use_brect, image, brect)    \n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        sequence.append(pre_processed_landmark_list)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (1265, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (250, 235, 245), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        #ROS action publish\n",
    "        \n",
    "        # Set the loop rate\n",
    "        rate = rospy.Rate(1) # 1 Hz\n",
    "\n",
    "        # Publish the actions in the list\n",
    "        action = actions[max_prob_index]\n",
    "        rospy.loginfo('Publishing action: %s', action)\n",
    "        pub.publish(action)\n",
    "        rate.sleep()\n",
    "        \n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', image) #cv2.flip(image, 1))\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        action_publisher()\n",
    "    except rospy.ROSInterruptException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e07f1bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[landmark {\n",
       "   x: 0.8205653429031372\n",
       "   y: 0.4372186064720154\n",
       "   z: 2.3218386502321664e-07\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7993267774581909\n",
       "   y: 0.43032246828079224\n",
       "   z: -0.017406750470399857\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7776250243186951\n",
       "   y: 0.40702715516090393\n",
       "   z: -0.026051992550492287\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7651407718658447\n",
       "   y: 0.3742293119430542\n",
       "   z: -0.032751407474279404\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7604789137840271\n",
       "   y: 0.3401475250720978\n",
       "   z: -0.0382261760532856\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7699438333511353\n",
       "   y: 0.3386610448360443\n",
       "   z: -0.011902453377842903\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7529102563858032\n",
       "   y: 0.29939010739326477\n",
       "   z: -0.023005390539765358\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7485141754150391\n",
       "   y: 0.2718585133552551\n",
       "   z: -0.032092660665512085\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7488373517990112\n",
       "   y: 0.24528968334197998\n",
       "   z: -0.03840484470129013\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7826817035675049\n",
       "   y: 0.3206998109817505\n",
       "   z: -0.009550678543746471\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7675331234931946\n",
       "   y: 0.2729939818382263\n",
       "   z: -0.018695548176765442\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7649290561676025\n",
       "   y: 0.24018308520317078\n",
       "   z: -0.026244448497891426\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7666102051734924\n",
       "   y: 0.21090222895145416\n",
       "   z: -0.0317203626036644\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7977449297904968\n",
       "   y: 0.3144872486591339\n",
       "   z: -0.00981924682855606\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7890036702156067\n",
       "   y: 0.2684638500213623\n",
       "   z: -0.020187389105558395\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7893871665000916\n",
       "   y: 0.23731563985347748\n",
       "   z: -0.02716139517724514\n",
       " }\n",
       " landmark {\n",
       "   x: 0.7920365333557129\n",
       "   y: 0.21055811643600464\n",
       "   z: -0.03171300143003464\n",
       " }\n",
       " landmark {\n",
       "   x: 0.8149733543395996\n",
       "   y: 0.3161512613296509\n",
       "   z: -0.011747858487069607\n",
       " }\n",
       " landmark {\n",
       "   x: 0.8144197463989258\n",
       "   y: 0.2796878516674042\n",
       "   z: -0.021451041102409363\n",
       " }\n",
       " landmark {\n",
       "   x: 0.8180942535400391\n",
       "   y: 0.2569018304347992\n",
       "   z: -0.026654954999685287\n",
       " }\n",
       " landmark {\n",
       "   x: 0.8221682906150818\n",
       "   y: 0.23537850379943848\n",
       "   z: -0.029906490817666054\n",
       " }]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afefe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98457b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.multi_hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ad5eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_processed_landmark_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7317d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2b8fa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 9.47689244992721e-10,\n",
       " -0.1673469387755102,\n",
       " -0.0326530612244898,\n",
       " -7.104796110367288e-05,\n",
       " -0.3346938775510204,\n",
       " -0.1346938775510204,\n",
       " -0.00010633466347139709,\n",
       " -0.4326530612244898,\n",
       " -0.27755102040816326,\n",
       " -0.00013367921418073225,\n",
       " -0.46938775510204084,\n",
       " -0.42857142857142855,\n",
       " -0.00015602520838075754,\n",
       " -0.39591836734693875,\n",
       " -0.43673469387755104,\n",
       " -4.8581442358542464e-05,\n",
       " -0.5306122448979592,\n",
       " -0.6081632653061224,\n",
       " -9.389955322353208e-05,\n",
       " -0.563265306122449,\n",
       " -0.7306122448979592,\n",
       " -0.0001309904516959677,\n",
       " -0.563265306122449,\n",
       " -0.8489795918367347,\n",
       " -0.00015675446816853115,\n",
       " -0.2979591836734694,\n",
       " -0.5142857142857142,\n",
       " -3.898236140304682e-05,\n",
       " -0.4163265306122449,\n",
       " -0.726530612244898,\n",
       " -7.630835990516507e-05,\n",
       " -0.43673469387755104,\n",
       " -0.8693877551020408,\n",
       " -0.00010712019795057725,\n",
       " -0.42448979591836733,\n",
       " -1.0,\n",
       " -0.00012947086777005876,\n",
       " -0.17959183673469387,\n",
       " -0.5428571428571428,\n",
       " -4.007855848390229e-05,\n",
       " -0.24897959183673468,\n",
       " -0.746938775510204,\n",
       " -8.239750655329957e-05,\n",
       " -0.24489795918367346,\n",
       " -0.8816326530612245,\n",
       " -0.00011086283745814342,\n",
       " -0.22448979591836735,\n",
       " -1.0,\n",
       " -0.00012944082216340667,\n",
       " -0.044897959183673466,\n",
       " -0.5346938775510204,\n",
       " -4.7950442804365745e-05,\n",
       " -0.04897959183673469,\n",
       " -0.6938775510204082,\n",
       " -8.75552698057525e-05,\n",
       " -0.02040816326530612,\n",
       " -0.7959183673469388,\n",
       " -0.00010879573469259301,\n",
       " 0.012244897959183673,\n",
       " -0.889795918367347,\n",
       " -0.00012206730945986145,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcf167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
